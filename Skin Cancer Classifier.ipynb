{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let’s define all the necessary libraries and let’s see what kind of data we’re dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory path\n",
    "\n",
    "base_dir = '/kaggle/input/skin-cancer-malignant-vs-benign'\n",
    "train_dir = base_dir + '/train'\n",
    "test_dir = base_dir +'/test'\n",
    "\n",
    "%matplotlib inline\n",
    "image = mpimg.imread(test_dir+'/benign/1003.jpg')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "image2 = mpimg.imread(test_dir+'/malignant/1007.jpg')\n",
    "plt.imshow(image2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is approximately 180MB in size. It might become a problem to feed the model with this amount of data, so we will be using the ImageDataGenerator.\n",
    "A Python generator is a neat way of passing a tuple of data to a model. Generator functions are a special kind of function that returns a lazy iterator. These are objects that you can loop over like a list. However, unlike lists, lazy iterators do not store their contents in memory.\n",
    "\n",
    "\n",
    "Data augmentation is a set of techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model. For full documentation, check the ImageDataGenerator docs on TensorFlow. There is no need to augment test data, since they serve as an evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1/255, rotation_range=30, shear_range=0.2, zoom_range=0.3, height_shift_range=0.4)\n",
    "test_gen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_dataset = train_gen.flow_from_directory(train_dir, target_size=(150,150),class_mode='binary', batch_size=64)\n",
    "test_dataset = test_gen.flow_from_directory(test_dir, target_size=(150,150),class_mode='binary', batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we set the target size to be 150x150 in the generator, we can easily define it in the first layer of our network.\n",
    "\n",
    "\n",
    "The model is comprised of three convolutional layers each followed by a pooling layer, a Flatten layer, and three dense layers, the last one being a sigmoid gate. The rest is history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Conv2D(64,(3,3), input_shape=(150,150,3), activation='relu', padding='SAME'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(32,(3,3), activation='relu', padding='SAME'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(16,(3,3), activation='relu', padding='SAME'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(optimizer = opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a look at what our model predicts for the pictures we plotted earlier. I have defined a simple function to do that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    np_image = img_to_array(image)\n",
    "    np_image = np.expand_dims(np_image, axis=0)\n",
    "    return model.predict(np_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
